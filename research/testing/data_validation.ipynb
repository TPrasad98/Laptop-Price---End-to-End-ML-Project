{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ten\\\\Desktop\\\\Laptop_Price\\\\research\\\\testing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict\n",
    "    preprocessed_data:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            STATUS_FILE=config.STATUS_FILE,\n",
    "            unzip_data_dir = config.unzip_data_dir,\n",
    "            all_schema=schema,\n",
    "            preprocessed_data=config.preprocessed_data\n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_processor_name(processor_name):\n",
    "    # Define regular expressions for extracting information\n",
    "    regexes = [\n",
    "        re.compile(r'(\\d+)(?:th|rd|st) Gen (Intel|AMD) (Core|i\\d+|Celeron|Pentium|Atom|Ryzen|Athlon) ?(\\w*)'),\n",
    "        re.compile(r'(Apple) (M1|M2(?: Pro)?(?: Max)?)'),\n",
    "        re.compile(r'(Intel) (Celeron|Pentium|Atom) (\\w+)'),\n",
    "        re.compile(r'(\\d+)(?:th|rd|st) Gen (Intel) (Celeron) (\\w+)'),\n",
    "        re.compile(r'(\\d+)(?:th|rd|st) Gen (Intel) (Pentium) (\\w+)'),\n",
    "        re.compile(r'(\\d+)(?:th|rd|st) Gen (Intel) (Core) (i\\d+) (\\w*)'),\n",
    "        re.compile(r'(\\d+)(?:th|rd|st) Gen (Intel) (Core) (i\\d+)'),\n",
    "    ]\n",
    "\n",
    "    # Match the regular expressions against the processor name\n",
    "    for regex in regexes:\n",
    "        match = regex.match(processor_name)\n",
    "        if match:\n",
    "            groups = match.groups()\n",
    "            if groups[0] == 'Apple':\n",
    "                return {'generation':'1','company': groups[0],'model_type': 'M1', 'version': groups[1]}\n",
    "            elif groups[0] == 'Intel':\n",
    "                if groups[2] in ['Celeron', 'Pentium', 'Atom']:\n",
    "                    return {'generation': groups[1], 'company': groups[0], 'model_type': groups[2], 'version': groups[3]}\n",
    "                elif groups[2] == 'Core':\n",
    "                    return {'generation': groups[1], 'company': groups[0], 'model_type': f'{groups[2]} {groups[4]}', 'version': groups[5]}\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return {'generation': groups[0], 'company': groups[1], 'model_type': groups[2], 'version': groups[3]}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def get_gpu_type(gpu_name):\n",
    "    # Define regular expressions for extracting GPU type information\n",
    "    regexes = [\n",
    "        re.compile(r'(NVIDIA|AMD)\\s*(Radeon)?'),\n",
    "        re.compile(r'(Apple)\\s*(Integrated Graphics)'),\n",
    "        re.compile(r'(Intel)\\s*(Iris Xe Graphics|UHD Graphics|HD Graphics|Graphics)?'),\n",
    "        re.compile(r'(ARM)\\s*(Mali G\\d+)'),\n",
    "    ]\n",
    "\n",
    "    # Match the regular expressions against the GPU name\n",
    "    for regex in regexes:\n",
    "        match = regex.search(gpu_name)\n",
    "        if match:\n",
    "            groups = match.groups()\n",
    "            gpu_type = groups[1] if len(groups) > 1 and groups[1] else groups[0] if groups[0] else None\n",
    "            return gpu_type\n",
    "\n",
    "    return None\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_cores_threads(cpu_name):\n",
    "    # Check for the presence of Cores and Threads in the name\n",
    "    cores_match = re.search(r'(\\d+|Dual|Quad|Hexa|Octa)\\s*Cores?', cpu_name)\n",
    "    threads_match = re.search(r'(\\d+)\\s*Threads?', cpu_name)\n",
    "\n",
    "    # Extract the number of cores and threads from the matches\n",
    "    cores = 0 if cores_match is None else cores_match.group(1)\n",
    "    threads = 0 if threads_match is None else threads_match.group(1)\n",
    "\n",
    "    # Convert 'Dual', 'Quad', 'Hexa', 'Octa' to corresponding numbers\n",
    "    cores_dict = {'Dual': 2, 'Quad': 4, 'Hexa': 6, 'Octa': 8}\n",
    "    cores = cores_dict.get(cores, cores)\n",
    "\n",
    "    return int(cores), int(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValiadtion:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def validate_all_columns(self)-> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "\n",
    "            data = pd.read_csv(self.config.preprocessed_data)\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "            \n",
    "            print(validation_status)\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "    def advanced_processing(self)-> bool:\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.unzip_data_dir)\n",
    "            all_cols = list(df.columns)\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            # Step 1 lets handle the processor column\n",
    "\n",
    "            processors = list(df['processor'])\n",
    "            new = []\n",
    "            for processor in processors:\n",
    "                 value = parse_processor_name(processor)\n",
    "                 new.append(value)\n",
    "            \n",
    "            processor_data = []\n",
    "            for obj in new:\n",
    "                if obj is None:\n",
    "                    processor_data.append([None,None,None,None])\n",
    "                else:\n",
    "                    processor_data.append([obj['company'],obj['generation'],obj['version'],obj['model_type']])\n",
    "            # adding new columns (feture engineering)\n",
    "            df[['processor_brand','processor_gen','processor_version','processor_model']] = processor_data\n",
    "\n",
    "\n",
    "            # Step 2 handle gpu column\n",
    "\n",
    "            gpus = list(df['GPU'])\n",
    "            gpu_data = []\n",
    "            for gpu in gpus:\n",
    "                value = get_gpu_type(gpu)\n",
    "                gpu_data.append(value)\n",
    "            # adding new column\n",
    "            df['gpu_type'] = gpu_data\n",
    "\n",
    "            \n",
    "            # Step 3 handling cpu column\n",
    "\n",
    "            cpu_data = []\n",
    "            for cpu in list(df['CPU']):\n",
    "                cpu_data.append(extract_cores_threads(cpu))\n",
    "            \n",
    "            # adding new columns\n",
    "            df[['cpu_core','cpu_threads']] = cpu_data\n",
    "\n",
    "\n",
    "            # Remove all unwanted columns from the data\n",
    "            data = df.drop(['Unnamed: 0.1', 'Unnamed: 0','name','processor','CPU','Ram_type','GPU','processor_model'],axis=1)\n",
    "\n",
    "            # handling Ram column\n",
    "            data.update(data['Ram'].apply(lambda x: int(x.split('GB')[0])))\n",
    "\n",
    "            # handling ROM\n",
    "            data.update(data['ROM'].apply(lambda x: int(x.split('GB')[0]) if 'GB' in x else int(x.split('TB')[0])*1024))\n",
    "\n",
    "            # handling ROM_type\n",
    "            data.update(data['ROM_type'].apply(lambda x: 1 if 'SSD' in x else 0))\n",
    "\n",
    "            # handling missing values in processor_gen column\n",
    "            data.update(data['processor_gen'].fillna(data['processor_gen'].mode()[0],inplace=True))\n",
    "\n",
    "            # handling missing values in processor_brand column\n",
    "            data.update(data['processor_brand'].fillna(data['processor_brand'].mode()[0],inplace=True))\n",
    "\n",
    "            # handling missing values in processor_model which depends on processor_brand\n",
    "            for brand in data['processor_brand'].value_counts().index:\n",
    "                data.update(data[data['processor_brand']==brand]['processor_version'].replace(np.nan,data[data['processor_brand']==brand]['processor_version'].mode()[0]))\n",
    "            \n",
    "            # handling missing values in gpu_type\n",
    "            data['gpu_type'].fillna(data['gpu_type'].mode()[0],inplace=True)\n",
    "\n",
    "            # OS column have little issue\n",
    "            data.update(data['OS'].replace('Windows 11  OS','Windows 11 OS'))\n",
    "            data.update(data['OS'].replace('Windows 10  OS','Windows 10 OS'))\n",
    "\n",
    "\n",
    "            # some os the colums have numerical values but their dtype is object so handling them\n",
    "            data[['Ram','ROM','ROM_type','processor_gen']] = data[['Ram','ROM','ROM_type','processor_gen']].apply(np.int64)\n",
    "            print(data.isnull().sum())\n",
    "            print(data.columns)\n",
    "            logger.info(\"Advanced pre processing is done\")\n",
    "\n",
    "            data.to_csv(self.config.preprocessed_data)\n",
    "\n",
    "            logger.info(\"data file saved to given path\")\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-10 18:04:23,775: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-10 18:04:23,787: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-10 18:04:23,791: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2023-12-10 18:04:23,793: INFO: common: created directory at: artifacts]\n",
      "[2023-12-10 18:04:23,794: INFO: common: created directory at: artifacts/data_validation]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand                0\n",
      "price                0\n",
      "spec_rating          0\n",
      "Ram                  0\n",
      "ROM                  0\n",
      "ROM_type             0\n",
      "display_size         0\n",
      "resolution_width     0\n",
      "resolution_height    0\n",
      "OS                   0\n",
      "warranty             0\n",
      "processor_brand      0\n",
      "processor_gen        0\n",
      "processor_version    0\n",
      "gpu_type             0\n",
      "cpu_core             0\n",
      "cpu_threads          0\n",
      "dtype: int64\n",
      "Index(['brand', 'price', 'spec_rating', 'Ram', 'ROM', 'ROM_type',\n",
      "       'display_size', 'resolution_width', 'resolution_height', 'OS',\n",
      "       'warranty', 'processor_brand', 'processor_gen', 'processor_version',\n",
      "       'gpu_type', 'cpu_core', 'cpu_threads'],\n",
      "      dtype='object')\n",
      "[2023-12-10 18:04:23,851: INFO: 1150478305: Advanced pre processing is done]\n",
      "[2023-12-10 18:04:23,859: INFO: 1150478305: data file saved to given path]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValiadtion(config=data_validation_config)\n",
    "    data_validation.advanced_processing()\n",
    "    data_validation.validate_all_columns()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
